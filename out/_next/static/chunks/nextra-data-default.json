{"/":{"title":"Introduction","data":{"":"the first OPEn  Respiratory Acoustic foundation model\npretraining and benchmarking system\n\n\nOPERA is a system that curates large-scale unlabelled respiratory audio datasets to pretrain audio encoders that are generalizable enough to be adapted for various health tasks with limited labeled data.\nOPERA:\nCurate a unique large-scale(~136K samples, 400+ hours), multi-source (5 datasets), multi-modal (breathing, coughing, and lung sounds) and publicly available (or under controlled access) dataset for model pretraining.\nPretrain 3 generalizable acoustic models with the curated unlabeled data using contrastive learning and generative pretraining, and release the model checkpoints.\nEmploy 10 labeled datasets (6 not covered by pretraining) to formulate 19 respiratory health tasks,  ensuring fair, comprehensive and reproducible downstream evaluation.\nEnable researchers and developers to extract feature using our model, or develop new models with our data and system, as a starting point for future exploration.\n\n\n\n\nPaper · ArXiv · Blog · GitHub Repository"}},"/blog":{"title":"Blog","data":{"":"Can AI leveraging respiratory sounds reveal our health status? The answer is yes, but the real question is: how?While acoustic AI is advancing rapidly in areas like speech recognition and virtual assistants, progress in health-related acoustic AI has been slower. A major obstacle is the scarcity of health-related audio data and pathological labels. Our system, OPERA, addresses this challenge by curating large-scale unlabelled respiratory audio datasets to pretrain audio encoders that can be adapted for various health tasks with limited labeled data. More importantly, OPERA is an open system, promoting accessibility and transparency in the safety-critical healthcare domain.\n\nOPERA curated a unique large-scale, unlabeled respiratory audio database (~136K samples, 404 hours) from five diverse sources. The audio covers breathing, coughing, and lung sounds, with all data publicly available (or under controlled access). This dataset is significantly larger than those used for training existing open acoustic models, providing a crucial resource for advancing health-related acoustic AI.The large-scale data enables us to pretrain foundational audio encoders. Since no labels are available, we deployed and compared two common self-supervised learning (SSL) strategies: contrastive learning, which captures similar representations for similar respiratory audio segments, and generative pretraining, which reconstructs the whole spectrum from parts of the audio. By relying solely on the audio itself, we ensure the generalizability of the pretrained encoders. These encoders can then be used as feature extractors for downstream health applications.\n\nIn addition to pretraining, OPERA offers 10 labeled datasets (6 not covered in pretraining) organized into 19 respiratory health tasks, including 12 focused on health condition inference and 7 on lung function estimation. This allows for a fair, comprehensive, and reproducible evaluation. Using linear probing, we directly assess the efficiency of the extracted representations. On this benchmark, our pretrained models outperform existing acoustic models on 16 out of 19 tasks and demonstrate strong generalization to unseen datasets and new respiratory audio types.SSL and foundation models are gaining momentum in machine learning for health because they reduce the labeling burden while maintaining generality and performance. OPERA marks a critical first step toward creating comprehensive and reproducible audio foundation models for health. Future research can build upon OPERA as an experimental resource, and healthcare applications can benefit from our foundation models as powerful feature extractors. This work expands the potential of machine learning, which now not only sees (through vision) and reads (through language) but also listens to our health (through audio)."}},"/publications":{"title":"Publications","data":{"":"Check the paper introducing OPERA datasets, pretrained models and the benchmark.","2024#2024":"Zhang Y, Xia T, Han J, Wu Y, Rizos G, Liu Y, Mosuily M, Chauhan J, Mascolo C. Towards open respiratory acoustic foundation models: Pretraining and benchmarking. In Thirty-eighth Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2024."}}}